{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('translated-ontonotes5.json') as fopen:\n",
    "    data = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107361"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = r\"\\b\\d+(?:[\\.,']\\d+)?\\b\"\n",
    "percentage = number + '%'\n",
    "money = r\"(?:(?:[$€£¢]|RM|rm)\\s*\\d+(?:[\\.,']\\d+)?(?:[MmKkBb](?:n|(?:il(?:lion)?))?)?)|(?:\\d+(?:[\\.,']\\d+)?(?:[MmKkBb](?:n|(?:il(?:lion)?))?)?\\s*(?:[$€£¢]|sen|ringgit|cent|penny))\"\n",
    "time = r'(?:(?:\\d+)?\\.?\\d+\\s*(?:AM|PM|am|pm|a\\.m\\.|p\\.m\\.))|(?:(?:[0-2]?[0-9]|[2][0-3]):(?:[0-5][0-9])(?::(?:[0-5][0-9]))?(?: ?(?:AM|PM|am|pm|a\\.m\\.|p\\.m\\.))?)'\n",
    "_short_date = r'(?:\\b(?<!\\d\\.)(?:(?:(?:[0123]?[0-9][\\.\\-\\/])?[0123]?[0-9][\\.\\-\\/][12][0-9]{3})|(?:[0123]?[0-9][\\.\\-\\/][0123]?[0-9][\\.\\-\\/][12]?[0-9]{2,3}))(?!\\.\\d)\\b)'\n",
    "_full_date_parts = [\n",
    "    # prefix\n",
    "    r'(?:(?<!:)\\b\\'?\\d{1,4},? ?)',\n",
    "    r'\\b(?:[Jj]an(?:uari)?|[Ff]eb(?:ruari)?|[Mm]a(?:c)?|[Aa]pr(?:il)?|[Mm]ei|[Jj]u(?:n)?|[Jj]ula(?:i)?|[Aa]ug(?:ust)?|[Oo]gos|[Ss]ept?(?:ember)?|[Oo]kt(?:ober)?|[Nn]ov(?:ember)?|[Dd]is(?:ember)?)\\b',\n",
    "    r'(?:(?:,? ?\\'?)?\\d{1,4}(?:st|nd|rd|n?th)?\\b(?:[,\\/]? ?\\'?\\d{2,4}[a-zA-Z]*)?(?: ?- ?\\d{2,4}[a-zA-Z]*)?(?!:\\d{1,4})\\b)',\n",
    "]\n",
    "_fd1 = '(?:{})'.format(\n",
    "    ''.join(\n",
    "        [_full_date_parts[0] + '?', _full_date_parts[1], _full_date_parts[2]]\n",
    "    )\n",
    ")\n",
    "_fd2 = '(?:{})'.format(\n",
    "    ''.join(\n",
    "        [_full_date_parts[0], _full_date_parts[1], _full_date_parts[2] + '?']\n",
    "    )\n",
    ")\n",
    "date = '(?:' + '(?:' + _fd1 + '|' + _fd2 + ')' + '|' + _short_date + ')'\n",
    "repeat_puncts =  r'([!?.]){2,}'\n",
    "quotes = r'\\\"(\\\\.|[^\\\"]){2,}\\\"'\n",
    "word = r'(?:[\\w_]+)'\n",
    "hypen = r'\\w+(?:-\\w+)+'\n",
    "hypen_left = r'\\w+(?: -\\w+)+'\n",
    "hypen_right = r'\\w+(?:- \\w+)+'\n",
    "hypen_both = r'\\w+(?: - \\w+)+'\n",
    "pipeline = [hypen, hypen_left, hypen_right, hypen_both, percentage, money, time, date, repeat_puncts,\n",
    "           number, word, '<ENAMEX.*?>(.+?)<.*?/.*?ENAMEX>',]\n",
    "pipeline.append('(?:\\S)')\n",
    "tok = re.compile(r'({})'.format('|'.join(pipeline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('memancing', '', ''),\n",
       " ('sial', '', ''),\n",
       " ('!', '', ''),\n",
       " ('1:00', '', ''),\n",
       " ('pagi', '', '')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.findall('memancing sial! 1:00 pagi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW',\n",
    "        'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'OTHER', 'PERCENT',\n",
    "        'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART']\n",
    "\n",
    "mapping = {'ACARA': 'EVENT', 'BAHASA': 'LANGUAGE', 'GEN': 'GPE',\n",
    "           'KADINAL': 'CARDINAL', 'KUANTITI': 'QUANTITY',\n",
    "           'Kawasan': 'LOC', 'MASA': 'TIME', 'ORANG': 'PERSON',\n",
    "          'PERATUS': 'PERCENT', 'PERIBADI': 'PERSON',\n",
    "          'PERISTIWA': 'EVENT', 'PRODUK': 'PRODUCT', 'TARIKH': 'DATE',\n",
    "          'UNDANG': 'LAW', 'WAKTU': 'TIME', 'WANG': 'MONEY', 'WONE': 'MONEY'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<ENAMEX TYPE = \"DATE\"> Gerakan hari ini </ENAMEX>',\n",
       "  '',\n",
       "  ' Gerakan hari ini '),\n",
       " ('hanya', '', ''),\n",
       " ('mendengar', '', ''),\n",
       " ('sebahagian', '', ''),\n",
       " ('daripada', '', ''),\n",
       " ('pertengkaran', '', ''),\n",
       " ('awal', '', ''),\n",
       " ('.', '', '')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.findall(data[0][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107361/107361 [00:13<00:00, 7809.72it/s]\n"
     ]
    }
   ],
   "source": [
    "tags = []\n",
    "reject = '<>\\\\{}/`'\n",
    "reject_words = ['DOC']\n",
    "for t in tqdm(data):\n",
    "    if t[1] is None:\n",
    "        continue\n",
    "    a = t\n",
    "    for t in tok.findall(t[1][1]):\n",
    "        if '<ENAMEX' in t[0] and 'ENAMEX>' in t[0]:\n",
    "#             cat = re.findall('(?:[\\w_]+)', t[0].split('>')[0])[-1]\n",
    "#             bs = BeautifulSoup(t[0])\n",
    "#             cat = bs.enamex.attrs.get('type', bs.enamex.attrs.get('jenis'))\n",
    "#             if cat is None:\n",
    "                \n",
    "#                 print(t, cat)\n",
    "            cat = re.findall('(?:[\\w_]+)', t[0].split('\">')[0].split('S_OFF')[0].split('E_OFF')[0])[-1]\n",
    "            text = t[-1]\n",
    "        else:\n",
    "            cat = 'OTHER'\n",
    "            text = t[0]\n",
    "        if 'ENAMEX' in text:\n",
    "            continue\n",
    "        \n",
    "        text = text.strip()\n",
    "        text = [t[0] for t in tok.findall(text) if t[0] not in reject and t[0] not in reject_words]\n",
    "        cat = cat.strip()\n",
    "        if cat not in categories:\n",
    "            try:\n",
    "                new_cat = re.findall('(?:[\\w_]+)', t[0].split('\">')[0].split('S_OFF')[0].split('E_OFF')[0])[2]\n",
    "                cat = new_cat\n",
    "            except:\n",
    "                cat = 'OTHER'\n",
    "        if cat not in categories:\n",
    "            cat = 'OTHER'\n",
    "        cat = mapping.get(cat, cat)\n",
    "        tags.extend([(t, cat) for t in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Gerakan', 'DATE'),\n",
       " ('hari', 'DATE'),\n",
       " ('ini', 'DATE'),\n",
       " ('hanya', 'OTHER'),\n",
       " ('mendengar', 'OTHER'),\n",
       " ('sebahagian', 'OTHER'),\n",
       " ('daripada', 'OTHER'),\n",
       " ('pertengkaran', 'OTHER'),\n",
       " ('awal', 'OTHER'),\n",
       " ('.', 'OTHER')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1815562"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181556"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_index = int(0.1 * 1815562)\n",
    "test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tags[:-test_index]\n",
    "test = tags[-test_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW',\n",
       "        'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'OTHER', 'PERCENT',\n",
       "        'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART'],\n",
       "       dtype='<U11'),\n",
       " array([  17180,   39578,    2700,    2941,   32172,     592,    1141,\n",
       "           4096,    9354,   12803,    2881,   56691, 1391417,    5596,\n",
       "          40814,    1827,    3280,    4324,    4619]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagging = [t[1] for t in train]\n",
    "np.unique(tagging, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW',\n",
       "        'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'OTHER', 'PERCENT',\n",
       "        'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART'],\n",
       "       dtype='<U11'),\n",
       " array([  2067,   6089,    109,    284,   3651,      8,    229,    447,\n",
       "          1699,    985,    202,  10159, 149218,   1436,   3643,    218,\n",
       "           368,    323,    421]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagging = [t[1] for t in test]\n",
    "np.unique(tagging, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed-train-ontonotes5.json', 'w') as fopen:\n",
    "    json.dump(train, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed-test-ontonotes5.json', 'w') as fopen:\n",
    "    json.dump(test, fopen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
