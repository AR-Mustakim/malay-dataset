{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huseinhouse-storage.s3-ap-southeast-1.amazonaws.com/bert-bahasa/singlish.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19870767"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('singlish.txt') as fopen:\n",
    "    singlish = fopen.read().split('\\n')\n",
    "    \n",
    "len(singlish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from unidecode import unidecode\n",
    "import cleaning\n",
    "from tqdm import tqdm\n",
    "\n",
    "def preprocessing(string):\n",
    "    string = unidecode(string)\n",
    "    string = re.sub(\n",
    "        'http\\S+|www.\\S+',\n",
    "        '',\n",
    "        ' '.join(\n",
    "            [i for i in string.split() if i.find('#') < 0 and i.find('@') < 0]\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    chars = ',.()!:\\'\"/;=-'\n",
    "    for c in chars:\n",
    "        string = string.replace(c, f' {c} ')\n",
    "        \n",
    "    string = re.sub('[^A-Za-z ]+', ' ', unidecode(string))\n",
    "    string = re.sub(r'[ ]+', ' ', string).strip()\n",
    "    \n",
    "    return string.lower()\n",
    "\n",
    "def loop(strings):\n",
    "    for i in tqdm(range(len(strings))):\n",
    "        strings[i] = preprocessing(strings[i])\n",
    "    return strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 764260/764260 [00:15<00:00, 48025.98it/s]\n",
      "100%|██████████| 764260/764260 [00:17<00:00, 44365.59it/s]\n",
      "100%|██████████| 764260/764260 [00:16<00:00, 47317.95it/s]\n",
      "100%|██████████| 764260/764260 [00:17<00:00, 44364.28it/s]\n",
      "100%|██████████| 764260/764260 [00:18<00:00, 42052.12it/s]\n",
      " 48%|████▊     | 365834/764260 [00:13<00:14, 27055.27it/s]\n",
      " 80%|████████  | 613460/764260 [00:16<00:03, 43587.20it/s]\n",
      " 52%|█████▏    | 400954/764260 [00:10<00:10, 34474.33it/s]\n",
      "100%|██████████| 764260/764260 [00:17<00:00, 42500.18it/s]\n",
      "100%|██████████| 7/7 [00:03<00:00,  1.97it/s]66387.35it/s]\n",
      "100%|██████████| 764260/764260 [00:19<00:00, 39579.85it/s]\n",
      "100%|██████████| 764260/764260 [00:18<00:00, 40796.38it/s]\n",
      "100%|██████████| 764260/764260 [00:19<00:00, 39787.89it/s]\n",
      "100%|██████████| 764260/764260 [00:16<00:00, 46932.26it/s]\n",
      " 78%|███████▊  | 597503/764260 [00:17<00:03, 42248.51it/s]\n",
      "100%|██████████| 764260/764260 [00:15<00:00, 49187.22it/s]\n",
      "100%|██████████| 764260/764260 [00:16<00:00, 47610.05it/s]\n",
      "100%|██████████| 764260/764260 [00:17<00:00, 43745.69it/s]\n",
      "100%|██████████| 764260/764260 [00:19<00:00, 38517.42it/s]\n",
      "100%|██████████| 764260/764260 [00:20<00:00, 37407.21it/s]\n",
      "100%|██████████| 764260/764260 [00:18<00:00, 41820.39it/s]\n",
      "100%|██████████| 764260/764260 [00:21<00:00, 35964.45it/s]\n",
      "100%|██████████| 764260/764260 [00:20<00:00, 37472.01it/s]\n",
      "100%|██████████| 764260/764260 [00:17<00:00, 42750.23it/s]\n",
      "100%|██████████| 764260/764260 [00:21<00:00, 35185.40it/s]\n",
      "100%|██████████| 764260/764260 [00:20<00:00, 38064.26it/s]\n",
      "100%|██████████| 764260/764260 [00:22<00:00, 33767.81it/s]\n"
     ]
    }
   ],
   "source": [
    "singlish = cleaning.multiprocessing(singlish, loop, cores = 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "527759"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singlish_words = set(' '.join(singlish).split())\n",
    "len(singlish_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/husein/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import malaya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "474399"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singlish_minus = singlish_words - malaya.texts._english_words._english_words\n",
    "len(singlish_minus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "manglish_vocab = {\n",
    "    'siasui', 'lah', 'chun', 'kapster', 'ah', 'leh', 'lansi', 'lan si', 'meh',\n",
    "    'stim', 'maluation', 'kantoi', 'seh', 'yam', 'hor', 'la', 'cha',\n",
    "    'tao', 'amoi', 'aiya', 'angmor', 'angpau', 'beng', 'chow', 'batam',\n",
    "    'liao', 'nian', 'buiji', 'hou', 'guo', 'jiang', 'chiu', 'buji',\n",
    "    'hao', 'kam', 'wan', 'yao', 'cao', 'ciao', 'jin', 'hoseh',\n",
    "    'jiak', 'ying', 'leybit', 'sibei', 'laobu', 'sia', 'cilok',\n",
    "    'cibai', 'cb', 'entao', 'gwai', 'kai', 'kongmong', 'kapcai',\n",
    "    'lanjiao', 'lancau', 'lalazai', 'momantai', 'paikia', 'paiseh',\n",
    "    'pokai', 'seow', 'sohai', 'sueh', 'tapau', 'wor', 'hor',\n",
    "    'terrer', 'chop', 'lansi', 'paiseh', 'syok', 'shiok',\n",
    "    'sibeh', 'kawkaw', 'abuden'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19870767/19870767 [00:48<00:00, 411396.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "manglish = []\n",
    "for s in tqdm(singlish):\n",
    "    if len(set(s.split()) & manglish_vocab):\n",
    "        manglish.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(849593, 19870767)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(manglish), len(singlish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('manglish.json', 'w') as fopen:\n",
    "    json.dump(manglish, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
