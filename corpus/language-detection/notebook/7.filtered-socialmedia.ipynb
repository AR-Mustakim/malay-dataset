{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import malaya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2408498, 8178139)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('filtered.json') as fopen:\n",
    "    filtered = json.load(fopen)\n",
    "\n",
    "with open('filtered_notin.json') as fopen:\n",
    "    filtered_notin = json.load(fopen)\n",
    "    \n",
    "len(filtered), len(filtered_notin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "# ind_filtered_notin, actual_filtered_notin = [], []\n",
    "# for s in tqdm(filtered_notin):\n",
    "#     if len(set(s.split()) & (ind_words)):\n",
    "#         ind_filtered_notin.append(s)\n",
    "#     else:\n",
    "#         actual_filtered_notin.append(s)\n",
    "        \n",
    "# len(ind_filtered_notin), len(actual_filtered_notin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from unidecode import unidecode\n",
    "import cleaning\n",
    "from tqdm import tqdm\n",
    "\n",
    "def preprocessing(string):\n",
    "    string = re.sub(\n",
    "        'http\\S+|www.\\S+',\n",
    "        '',\n",
    "        ' '.join(\n",
    "            [i for i in string.split() if i.find('#') < 0 and i.find('@') < 0]\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    chars = ',.()!:\\'\"/;=-'\n",
    "    for c in chars:\n",
    "        string = string.replace(c, f' {c} ')\n",
    "        \n",
    "    string = re.sub(\n",
    "        u'[0-9!@#$%^&*()_\\-+{}|\\~`\\'\";:?/.>,<]',\n",
    "        ' ',\n",
    "        string,\n",
    "        flags = re.UNICODE,\n",
    "    )\n",
    "    string = re.sub(r'[ ]+', ' ', string).strip()\n",
    "    \n",
    "    return string.lower()\n",
    "\n",
    "def loop(strings):\n",
    "    for i in tqdm(range(len(strings))):\n",
    "        strings[i] = preprocessing(strings[i])\n",
    "    return strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150531/150531 [00:02<00:00, 53603.92it/s]\n",
      "100%|██████████| 150531/150531 [00:02<00:00, 51224.12it/s]\n",
      " 62%|██████▏   | 93406/150531 [00:02<00:01, 41895.36it/s]]\n",
      " 60%|█████▉    | 89793/150531 [00:02<00:01, 40711.81it/s]]\n",
      "100%|██████████| 150531/150531 [00:02<00:00, 53497.55it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 10305.42it/s]\n",
      "100%|██████████| 150531/150531 [00:02<00:00, 53768.46it/s]\n",
      "100%|██████████| 150531/150531 [00:02<00:00, 52100.51it/s]\n",
      "100%|██████████| 150531/150531 [00:02<00:00, 52444.54it/s]\n",
      "100%|██████████| 150531/150531 [00:02<00:00, 51223.92it/s]\n",
      "100%|██████████| 150531/150531 [00:03<00:00, 41151.19it/s]\n",
      "100%|██████████| 150531/150531 [00:03<00:00, 41450.67it/s]\n",
      "100%|██████████| 150531/150531 [00:03<00:00, 40029.81it/s]\n",
      "100%|██████████| 150531/150531 [00:03<00:00, 41882.96it/s]\n",
      "100%|██████████| 150531/150531 [00:03<00:00, 40253.96it/s]\n",
      "100%|██████████| 150531/150531 [00:08<00:00, 18467.94it/s]\n",
      "100%|██████████| 150531/150531 [00:11<00:00, 13425.54it/s]\n"
     ]
    }
   ],
   "source": [
    "ind_filtered_notin = cleaning.multiprocessing(filtered, loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 511133/511133 [00:08<00:00, 61279.70it/s]\n",
      "100%|██████████| 511133/511133 [00:08<00:00, 59567.46it/s]\n",
      " 98%|█████████▊| 499058/511133 [00:08<00:00, 62116.56it/s]\n",
      "100%|██████████| 511133/511133 [00:08<00:00, 60665.98it/s]\n",
      "100%|██████████| 511133/511133 [00:08<00:00, 62158.87it/s]\n",
      "\n",
      " 95%|█████████▌| 486271/511133 [00:07<00:00, 62535.65it/s]\n",
      "100%|██████████| 511133/511133 [00:08<00:00, 61223.77it/s]\n",
      "100%|██████████| 511133/511133 [00:08<00:00, 62190.96it/s]\n",
      "100%|██████████| 511133/511133 [00:08<00:00, 60388.68it/s]\n",
      "100%|██████████| 511133/511133 [00:08<00:00, 61465.24it/s]\n",
      "100%|██████████| 511133/511133 [00:09<00:00, 52934.83it/s]\n",
      "100%|██████████| 511133/511133 [00:09<00:00, 52370.98it/s]\n",
      "100%|██████████| 511133/511133 [00:09<00:00, 51398.09it/s]\n",
      "100%|██████████| 511133/511133 [00:09<00:00, 52311.53it/s]\n",
      " 48%|████▊     | 246256/511133 [00:09<00:11, 22374.57it/s]\n",
      "100%|██████████| 511133/511133 [00:21<00:00, 23873.14it/s]\n"
     ]
    }
   ],
   "source": [
    "actual_filtered_notin = cleaning.multiprocessing(filtered_notin, loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2408498, 8178139)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ind_filtered_notin), len(actual_filtered_notin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('english-words.json') as fopen:\n",
    "    english_words = set(json.load(fopen))\n",
    "    \n",
    "with open('malays_word.json') as fopen:\n",
    "    malays = set(json.load(fopen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('counts_1grams-second.txt') as fopen:\n",
    "#     count = list(filter(None, fopen.read().split('\\n')))\n",
    "    \n",
    "# with open('counts_1grams.txt') as fopen:\n",
    "#     count.extend(list(filter(None, fopen.read().split('\\n'))))\n",
    "    \n",
    "# count = set([c.split('\\t')[0] for c in count])\n",
    "# len(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272249"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_words = malaya.texts._english_words._english_words | english_words\n",
    "len(english_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272249"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_minus = english_words - malays\n",
    "len(english_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131799"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_minus = {i for i in english_minus if 'haha' not in i and i != 'rt' and 'yeay' not in i and\\\n",
    "                'yes' not in i and 'ooo' not in i and 'insha' not in i and 'huhu' not in i and\\\n",
    "                'insya' not in i and 'hew' not in i and 'uwuu' not in i and\\\n",
    "                 'wkwk' not in i and 'hoho' not in i and\\\n",
    "                 'meow' not in i and 'aiii' not in i and 'alham' not in i and 'mashaa' not in i\\\n",
    "                 and i not in ['takda', 'cer']}\n",
    "\n",
    "len(english_minus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8178139/8178139 [00:26<00:00, 305353.03it/s]\n"
     ]
    }
   ],
   "source": [
    "rojak, malays = [], []\n",
    "for s in tqdm(actual_filtered_notin):\n",
    "    if len(set(s.split()) & english_minus):\n",
    "        rojak.append(s)\n",
    "    else:\n",
    "        malays.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(947237, 7230902)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rojak), len(malays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dia dah tua put dah nak plus dia tak start regularly kat man utd so mesti ka',\n",
       " 'guys tolong rt tweet ni sampai owner dia dapat phone ni tertinggal kat belakang teksi pakcik saya model oppo r s',\n",
       " 'jenis jenis orang stalking di media sosial pakai akun palsu pakai akun temannya sanak saudaranya handai tau',\n",
       " 'ajax spurs lah anti menstrim',\n",
       " 'lia pulang mereka semuanya pedo kecuali aku jangan mau',\n",
       " 'nice igstory harini dah tak nmpak org repost sudan meal project tu',\n",
       " 'beomgyu ngambilin confetti yang nyangkut di rambut jimin dong liat gini aja soft akutuh cha',\n",
       " 'bts at rose bowl day jadi mulai hari ini aku akan berusaha menjadi dokter strange karena cincin ini',\n",
       " 'bukan sengaja nak samakan tapi tu laaa dah ter sama kan obvious okayyy',\n",
       " 'bolehhhh hehehe']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rojak[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['memiliki sedikit iman lebih berharga dari pada memiliki segudang emas',\n",
       " 'on jadahnyaaa in sorry bad english hihuheheho',\n",
       " 'sis tak faham apa yang mungkin ini puncanya tu',\n",
       " 'sejarah susah',\n",
       " 'loop in nama dlm email pon boleh jd issue dah org email aku reply all jelaaa ade mase pulak aku nak tengok satu nama recipients',\n",
       " 'tak sakit pun tapi saja nak bau minyak freshcare sbb bau lavender',\n",
       " 'rosmah',\n",
       " 'bila kau tengah feeling lagu raya',\n",
       " 'kekasih bayangan',\n",
       " 'hidup ni jgn terlalu nk mendongak ke atas nanti jatuh padan muka kau']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malays[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ternyata kl lg sdih bisa ngasilin makanan enak',\n",
       " 'abu kampret',\n",
       " 'bapa saya suka pake oppo saya sukanya nokia kaka saya sukanya samsung yg penting punya hape aja',\n",
       " 'ngelamar kasih cincin tp kok mukanya songong ya sedih gue liatnya',\n",
       " 'caption iki nggarai uwong males nikah min ya kali manusia arep punah ngunu neg gak nikah',\n",
       " 'pertanyaannya sederhana jika kami memang dukung prabowo ngapain selama kampanye kemarin capek dukung jokowi sampa',\n",
       " 'untuk mengamankan suara partai ahmad rofiq selaku sekjen partai perindo meminta kepada seluruh caleg dan struktur',\n",
       " 'dom jakpus sih bebas mau ketemuan or shopee',\n",
       " 'bisa dapet duit ini kaga punya mobil juga kan kaya gemer gemer ini kaga',\n",
       " 'valentino rossi tidak setuju kompetisi motogp dimulai dari eropa']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_filtered_notin[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('social-language.json', 'w') as fopen:\n",
    "    json.dump({'rojak': rojak,\n",
    "              'malay': malays,\n",
    "              'ind': ind_filtered_notin}, fopen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
