{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import squad_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
    "# !wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
    "# !wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\n",
    "# !wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import subprocess\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import malaya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train-v2.0.json') as hn:\n",
    "    content = json.load(hn)\n",
    "\n",
    "squad_version = content['version']\n",
    "titles = [data['title'] for data in content['data']]\n",
    "context_sentences = [\n",
    "    context_sentence\n",
    "    for data in content['data']\n",
    "    for paragraph in data['paragraphs']\n",
    "    for context_sentence in malaya.text.function.split_into_sentences(\n",
    "        utils.remove_line_breaks(paragraph['context']), minimum_length = 2\n",
    "    )\n",
    "    if context_sentence\n",
    "]\n",
    "\n",
    "questions = [\n",
    "    qa['question']\n",
    "    for data in content['data']\n",
    "    for paragraph in data['paragraphs']\n",
    "    for qa in paragraph['qas']\n",
    "    if qa['question']\n",
    "]\n",
    "\n",
    "answers = [\n",
    "    answer['text']\n",
    "    for data in content['data']\n",
    "    for paragraph in data['paragraphs']\n",
    "    for qa in paragraph['qas']\n",
    "    for answer in qa['answers']\n",
    "    if answer['text']\n",
    "]\n",
    "\n",
    "if squad_version == 'v2.0':\n",
    "    plausible_answers = []\n",
    "    for data in content['data']:\n",
    "        for paragraph in data['paragraphs']:\n",
    "            for qa in paragraph['qas']:\n",
    "                if qa['is_impossible']:\n",
    "                    for answer in qa['plausible_answers']:\n",
    "                        plausible_answers.append(answer['text'])\n",
    "else:\n",
    "    plausible_answers = []\n",
    "\n",
    "content = titles + context_sentences + questions + answers + plausible_answers\n",
    "content = set(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'translated-train-2.0.json'\n",
    "batch_size = 10\n",
    "\n",
    "if os.path.exists(file):\n",
    "    with open(file) as fopen:\n",
    "        data = json.load(fopen)\n",
    "    list_content, translated = data\n",
    "    \n",
    "else:\n",
    "    list_content = list(content)\n",
    "    transformer = malaya.translation.en_ms.transformer()\n",
    "\n",
    "    translated = []\n",
    "    for i in tqdm(range(0, len(list_content), batch_size)):\n",
    "        translated.extend(transformer.greedy_decoder(list_content[i: i + batch_size]))\n",
    "        \n",
    "    with open(file, 'w') as fopen:\n",
    "        json.dump([list_content, translated], fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'content_translations_alignments-train-2.0.json'\n",
    "\n",
    "if os.path.exists(file):\n",
    "    with open(file) as fopen:\n",
    "        content_translations_alignments = json.load(fopen)\n",
    "        \n",
    "else:\n",
    "    context_sentence_questions_answers_alignments = utils.compute_alignment(\n",
    "        list_content, 'en', translated, 'ms', 'forward', 'train-v2.0.json', 'out'\n",
    "    )\n",
    "\n",
    "    content_translations_alignments = {}\n",
    "    for sentence, sentence_translated, alignment in zip(\n",
    "        list_content, translated, context_sentence_questions_answers_alignments\n",
    "    ):\n",
    "        content_translations_alignments[sentence] = {\n",
    "            'translation': sentence_translated,\n",
    "            'alignment': alignment,\n",
    "        }\n",
    "        \n",
    "    with open(file, 'w') as fopen:\n",
    "        json.dump(content_translations_alignments, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [12:06<00:00,  1.64s/it]\n"
     ]
    }
   ],
   "source": [
    "answers_from_alignment = True\n",
    "\n",
    "with open('train-v2.0.json') as hn:\n",
    "    content = json.load(hn)\n",
    "\n",
    "squad_version = content['version']\n",
    "\n",
    "for data in tqdm(content['data']):\n",
    "    title = data['title']\n",
    "    data['title'] = content_translations_alignments[title]['translation']\n",
    "    for paragraphs in data['paragraphs']:\n",
    "        context = paragraphs['context']\n",
    "\n",
    "        context_sentences = [\n",
    "            s\n",
    "            for s in malaya.text.function.split_into_sentences(\n",
    "                utils.remove_line_breaks(context), minimum_length = 2\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        context_translated = ' '.join(\n",
    "            content_translations_alignments[s]['translation']\n",
    "            for s in context_sentences\n",
    "        )\n",
    "        context_alignment_tok = utils.compute_context_alignment(\n",
    "            [\n",
    "                content_translations_alignments[s]['alignment']\n",
    "                for s in context_sentences\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        paragraphs['context'] = context_translated\n",
    "        for qa in paragraphs['qas']:\n",
    "            question = qa['question']\n",
    "            question_translated = content_translations_alignments[question][\n",
    "                'translation'\n",
    "            ]\n",
    "            qa['question'] = question_translated\n",
    "\n",
    "            # Translate answers and plausible answers for SQUAD v2.0\n",
    "            if squad_version == 'v2.0':\n",
    "                if not qa['is_impossible']:\n",
    "                    for answer in qa['answers']:\n",
    "                        answer_translated = content_translations_alignments[\n",
    "                            answer['text']\n",
    "                        ]['translation']\n",
    "                        answer_translated, answer_translated_start = utils.extract_answer_translated(\n",
    "                            answer,\n",
    "                            answer_translated,\n",
    "                            context,\n",
    "                            context_translated,\n",
    "                            context_alignment_tok,\n",
    "                            answers_from_alignment,\n",
    "                        )\n",
    "                        answer['text'] = answer_translated\n",
    "                        answer['answer_start'] = answer_translated_start\n",
    "\n",
    "                else:\n",
    "                    for plausible_answer in qa['plausible_answers']:\n",
    "                        plausible_answer_translated = content_translations_alignments[\n",
    "                            plausible_answer['text']\n",
    "                        ][\n",
    "                            'translation'\n",
    "                        ]\n",
    "                        answer_translated, answer_translated_start = utils.extract_answer_translated(\n",
    "                            plausible_answer,\n",
    "                            plausible_answer_translated,\n",
    "                            context,\n",
    "                            context_translated,\n",
    "                            context_alignment_tok,\n",
    "                            answers_from_alignment,\n",
    "                        )\n",
    "                        plausible_answer['text'] = answer_translated\n",
    "                        plausible_answer[\n",
    "                            'answer_start'\n",
    "                        ] = answer_translated_start\n",
    "\n",
    "            # Translate answers for SQUAD v1.1\n",
    "            else:\n",
    "                for answer in qa['answers']:\n",
    "                    answer_translated = content_translations_alignments[\n",
    "                        answer['text']\n",
    "                    ]['translation']\n",
    "                    answer_translated, answer_translated_start = utils.extract_answer_translated(\n",
    "                        answer,\n",
    "                        answer_translated,\n",
    "                        context,\n",
    "                        context_translated,\n",
    "                        context_alignment_tok,\n",
    "                        answers_from_alignment,\n",
    "                    )\n",
    "                    answer['text'] = answer_translated\n",
    "                    answer['answer_start'] = answer_translated_start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "442it [00:01, 424.34it/s]\n"
     ]
    }
   ],
   "source": [
    "content_translated = content\n",
    "content_cleaned = {'version': content['version'], 'data': []}\n",
    "total_answers = 0\n",
    "total_correct_plausible_answers = 0\n",
    "total_correct_answers = 0\n",
    "for idx_data, data in tqdm(enumerate(content_translated['data'])):\n",
    "    content_title = content_translated['data'][idx_data]['title']\n",
    "    content_cleaned['data'].append({'title': content_title, 'paragraphs': []})\n",
    "    for par in data['paragraphs']:\n",
    "        qas_cleaned = []\n",
    "        for idx_qa, qa in enumerate(par['qas']):\n",
    "            question = qa['question']\n",
    "\n",
    "            # Extract answers and plausible answers for SQUAD v2.0\n",
    "            if squad_version == 'v2.0':\n",
    "                if not qa['is_impossible']:\n",
    "                    correct_answers = []\n",
    "                    for a in qa['answers']:\n",
    "                        total_answers += 1\n",
    "                        if a['text']:\n",
    "                            total_correct_answers += 1\n",
    "                            correct_answers.append(a)\n",
    "                    correct_plausible_answers = []\n",
    "                else:\n",
    "                    correct_plausible_answers = []\n",
    "                    for pa in qa['plausible_answers']:\n",
    "                        total_answers += 1\n",
    "                        if pa['text']:\n",
    "                            total_correct_plausible_answers += 1\n",
    "                            correct_plausible_answers.append(pa)\n",
    "                    correct_answers = []\n",
    "\n",
    "                # add answers and plausible answers to the content cleaned\n",
    "                if correct_answers:\n",
    "                    content_qas_id = qa['id']\n",
    "                    content_qas_is_impossible = qa['is_impossible']\n",
    "                    correct_answers_from_context = []\n",
    "                    for a in qa['answers']:\n",
    "                        start = a['answer_start']\n",
    "                        correct_answers_from_context.append(\n",
    "                            {\n",
    "                                'text': par['context'][\n",
    "                                    start : start + len(a['text'])\n",
    "                                ],\n",
    "                                'answer_start': start,\n",
    "                            }\n",
    "                        )\n",
    "                    qa_cleaned = {\n",
    "                        'question': question,\n",
    "                        'answers': correct_answers_from_context,\n",
    "                        'id': content_qas_id,\n",
    "                        'is_impossible': content_qas_is_impossible,\n",
    "                    }\n",
    "                    qas_cleaned.append(qa_cleaned)\n",
    "                if correct_plausible_answers and not correct_answers:\n",
    "                    content_qas_id = qa['id']\n",
    "                    content_qas_is_impossible = qa['is_impossible']\n",
    "                    correct_answers_from_context = []\n",
    "                    for a in qa['answers']:\n",
    "                        start = a['answer_start']\n",
    "                        correct_answers_from_context.append(\n",
    "                            {\n",
    "                                'text': par['context'][\n",
    "                                    start : start + len(a['text'])\n",
    "                                ],\n",
    "                                'answer_start': start,\n",
    "                            }\n",
    "                        )\n",
    "                    qa_cleaned = {\n",
    "                        'question': question,\n",
    "                        'answers': correct_answers,\n",
    "                        'plausible_answers': correct_plausible_answers,\n",
    "                        'id': content_qas_id,\n",
    "                        'is_impossible': content_qas_is_impossible,\n",
    "                    }\n",
    "                    qas_cleaned.append(qa_cleaned)\n",
    "\n",
    "            # Extract answers for SQUAD v1.0\n",
    "            else:\n",
    "                correct_answers = []\n",
    "                for a in qa['answers']:\n",
    "                    total_answers += 1\n",
    "                    if a['text']:\n",
    "                        total_correct_answers += 1\n",
    "                        correct_answers.append(a)\n",
    "\n",
    "                # add answers and plausible answers to the content cleaned\n",
    "                if correct_answers:\n",
    "                    content_qas_id = qa['id']\n",
    "                    correct_answers_from_context = []\n",
    "                    for a in qa['answers']:\n",
    "                        start = a['answer_start']\n",
    "                        correct_answers_from_context.append(\n",
    "                            {\n",
    "                                'text': par['context'][\n",
    "                                    start : start + len(a['text'])\n",
    "                                ],\n",
    "                                'answer_start': start,\n",
    "                            }\n",
    "                        )\n",
    "                    qa_cleaned = {\n",
    "                        'question': question,\n",
    "                        'answers': correct_answers_from_context,\n",
    "                        'id': content_qas_id,\n",
    "                    }\n",
    "                    qas_cleaned.append(qa_cleaned)\n",
    "\n",
    "        # Add the paragraph only if there are non-empty question-answer examples inside\n",
    "        if qas_cleaned:\n",
    "            content_context = par['context']\n",
    "            content_cleaned['data'][idx_data]['paragraphs'].append(\n",
    "                {'context': content_context, 'qas': qas_cleaned}\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ms-train-2.0.json', 'w') as fn:\n",
    "    json.dump(content_cleaned, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of translated examples (correct answers/total answers): 130318/130319 = 100.0%\n",
      "No. of answers: 86821\n",
      "No. of plausible answers: 43497\n"
     ]
    }
   ],
   "source": [
    "if squad_version == 'v2.0':\n",
    "    total_correct = total_correct_answers + total_correct_plausible_answers\n",
    "    accuracy = round((total_correct / total_answers) * 100, 2)\n",
    "    print(\n",
    "        'Percentage of translated examples (correct answers/total answers): {}/{} = {}%\\n'\n",
    "        'No. of answers: {}\\n'\n",
    "        'No. of plausible answers: {}'.format(\n",
    "            total_correct,\n",
    "            total_answers,\n",
    "            accuracy,\n",
    "            total_correct_answers,\n",
    "            total_correct_plausible_answers,\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Count correct answers\n",
    "else:\n",
    "    total_correct = total_correct_answers\n",
    "    accuracy = round((total_correct / total_answers) * 100, 2)\n",
    "    print(\n",
    "        'Percentage of translated examples (correct answers/total answers): {}/{} = {}%\\n'\n",
    "        'No. of answers: {}'.format(\n",
    "            total_correct, total_answers, accuracy, total_correct_answers\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
